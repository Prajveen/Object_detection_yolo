{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: pillow in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (10.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: torchvision in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (0.17.1)\n",
      "Requirement already satisfied: matplotlib in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.1 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from torch==2.2.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from torch==2.2.1->torchvision) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from torch==2.2.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from torch==2.2.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from torch==2.2.1->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from torch==2.2.1->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: pillow in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (10.2.0)\n",
      "Requirement already satisfied: pandas in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: pyarrow in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (15.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python pillow\n",
    "!pip install torchvision matplotlib\n",
    "!pip install pillow pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_images_df = pd.read_parquet('easy-500/images.parquet')\n",
    "easy_labels_df = pd.read_parquet('easy-500/labels.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              image\n",
       "0   0  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_images_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>orientation</th>\n",
       "      <th>radius</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "      <td>299</td>\n",
       "      <td>0.663225</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>539</td>\n",
       "      <td>427</td>\n",
       "      <td>0.610865</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>148</td>\n",
       "      <td>0.488692</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>136</td>\n",
       "      <td>2.426008</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>846</td>\n",
       "      <td>448</td>\n",
       "      <td>4.660029</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>613</td>\n",
       "      <td>248</td>\n",
       "      <td>6.003933</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>214</td>\n",
       "      <td>2.391101</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>657</td>\n",
       "      <td>387</td>\n",
       "      <td>5.393067</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>752</td>\n",
       "      <td>311</td>\n",
       "      <td>2.792527</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>657</td>\n",
       "      <td>134</td>\n",
       "      <td>2.565634</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>699</td>\n",
       "      <td>245</td>\n",
       "      <td>3.019420</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>308</td>\n",
       "      <td>382</td>\n",
       "      <td>4.537856</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>926</td>\n",
       "      <td>116</td>\n",
       "      <td>6.021386</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>0.506145</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>120</td>\n",
       "      <td>3.333579</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>307</td>\n",
       "      <td>5.724680</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>390</td>\n",
       "      <td>3.106686</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>275</td>\n",
       "      <td>2.234021</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>181</td>\n",
       "      <td>1.727876</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>297</td>\n",
       "      <td>3.246312</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>934</td>\n",
       "      <td>295</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>865</td>\n",
       "      <td>223</td>\n",
       "      <td>0.698132</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id    x    y  orientation  radius  class\n",
       "0          0  269  450     0.000000      17      0\n",
       "1          0  533  299     0.663225      45      1\n",
       "2          0  539  427     0.610865      46      1\n",
       "3          0  365  148     0.488692      45      1\n",
       "4          0  472  136     2.426008      40      1\n",
       "5          0  846  448     4.660029      41      1\n",
       "6          0  613  248     6.003933      41      1\n",
       "7          0  287  214     2.391101      48      1\n",
       "8          0  657  387     5.393067      44      1\n",
       "9          0  752  311     2.792527      41      1\n",
       "10         0  657  134     2.565634      49      1\n",
       "11         0  699  245     3.019420      38      1\n",
       "12         0  308  382     4.537856      39      2\n",
       "13         0  926  116     6.021386      39      2\n",
       "14         0  398  398     0.506145      42      2\n",
       "15         0  774  120     3.333579      47      2\n",
       "16         0  221  307     5.724680      48      2\n",
       "17         0  129  390     3.106686      49      2\n",
       "18         0  362  275     2.234021      38      2\n",
       "19         0  173  181     1.727876      41      2\n",
       "20         0  109  297     3.246312      41      2\n",
       "21         0  934  295     0.087266      40      2\n",
       "22         0  865  223     0.698132      40      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_labels_df.head(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 2), (11500, 6))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_images_df.shape , easy_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the first image: (512, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "def decode_image(image_data):\n",
    "    nparr = np.frombuffer(image_data, np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "easy_images_df['image'] = easy_images_df['image'].apply(decode_image)\n",
    "\n",
    "# Size of each image\n",
    "print(f\"\\nShape of the first image: {easy_images_df['image'].iloc[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[17, 123, 57], [18, 124, 58], [18, 124, 58],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[17, 123, 57], [18, 124, 58], [18, 124, 58],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[[17, 123, 57], [18, 124, 58], [18, 124, 58],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[[17, 123, 57], [18, 124, 58], [18, 124, 58],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[[17, 123, 57], [18, 124, 58], [18, 124, 58],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              image\n",
       "0   0  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...\n",
       "1   1  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...\n",
       "2   2  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...\n",
       "3   3  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...\n",
       "4   4  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_images_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, images, labels, grid_size, scale_factor=0.5):\n",
    "        self.grid_size = grid_size\n",
    "        self.scale_factor = scale_factor\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)  # Return the length of the dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_data = self.images.loc[idx, 'image']\n",
    "        image_data = self.transform(image_data)\n",
    "        labels_data = self.labels.loc[idx].values.astype(np.float32)  # Convert labels to numpy array and then to tensor\n",
    "        labels_data = torch.tensor(labels_data)\n",
    "        return image_data, labels_data\n",
    "\n",
    "    def scale_image(self, image):\n",
    "        width = int(image.shape[1] * self.scale_factor)\n",
    "        height = int(image.shape[0] * self.scale_factor)\n",
    "        resized_image = cv2.resize(image, (width, height))\n",
    "        return resized_image\n",
    "\n",
    "    def normalize_image(self, image):\n",
    "        normalized_image = image / 255.0  # Assuming image is in uint8 format\n",
    "        return normalized_image\n",
    "\n",
    "    def calculate_relative_coordinates(self, x, y, radius, orientation, image_width, image_height):\n",
    "        grid_width = image_width / self.grid_size[1]\n",
    "        grid_height = image_height / self.grid_size[0]\n",
    "        x = x * self.scale_factor\n",
    "        y = y * self.scale_factor\n",
    "        r = radius * self.scale_factor\n",
    "        grid_x = int(x / grid_width)\n",
    "        grid_y = int(y / grid_height)\n",
    "        relative_x = round((x - grid_x * grid_width) / grid_width, 4)\n",
    "        relative_y = round((y - grid_y * grid_height) / grid_height, 4)\n",
    "        relative_radius = round(r, 4)\n",
    "        o = round(orientation, 4)\n",
    "        return relative_x, relative_y, relative_radius, o\n",
    "\n",
    "    def preprocess_labels(self, image_width, image_height):\n",
    "        num_images = len(self.images)\n",
    "        labels_array = np.zeros((num_images, self.grid_size[0], self.grid_size[1], 8), dtype=np.float32)\n",
    "\n",
    "        for idx, image_id in enumerate(self.labels['image_id'].unique()):\n",
    "            image_labels = self.labels[self.labels['image_id'] == image_id]\n",
    "            for _, row in image_labels.iterrows():\n",
    "                x, y, radius, orientation = row['x'], row['y'], row['radius'], row['orientation']\n",
    "                relative_x, relative_y, relative_radius, o = self.calculate_relative_coordinates(x, y, radius, orientation, image_width, image_height)\n",
    "\n",
    "                grid_width = image_width / self.grid_size[1]\n",
    "                grid_height = image_height / self.grid_size[0]\n",
    "                grid_x = int(x / grid_width)\n",
    "                grid_y = int(y / grid_height)\n",
    "\n",
    "                grid_x = min(max(grid_x, 0), self.grid_size[1] - 1)\n",
    "                grid_y = min(max(grid_y, 0), self.grid_size[0] - 1)\n",
    "\n",
    "                confidence_score = 1\n",
    "                class_label = int(row['class'])\n",
    "                one_hot_class = np.zeros(3)\n",
    "                one_hot_class[class_label] = 1\n",
    "\n",
    "                labels_array[idx, grid_y, grid_x, 0] = relative_x\n",
    "                labels_array[idx, grid_y, grid_x, 1] = relative_y\n",
    "                labels_array[idx, grid_y, grid_x, 2] = relative_radius\n",
    "                labels_array[idx, grid_y, grid_x, 3] = o\n",
    "                labels_array[idx, grid_y, grid_x, 4] = confidence_score\n",
    "                labels_array[idx, grid_y, grid_x, 5:] = one_hot_class\n",
    "\n",
    "        return torch.tensor(labels_array)\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.images['scaled_image'] = self.images['image'].apply(self.scale_image)\n",
    "        self.images['normalized_image'] = self.images['scaled_image'].apply(self.normalize_image)\n",
    "        labels_array = []\n",
    "\n",
    "        for i, row in self.images.iterrows():\n",
    "            image_height, image_width, _ = row['scaled_image'].shape\n",
    "            labels_array.append(self.preprocess_labels(image_width, image_height))\n",
    "\n",
    "        return self.images, torch.stack(labels_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/hx_5zpz14q7bx518_v0994xc0000gn/T/ipykernel_33983/2152103249.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.images['scaled_image'] = self.images['image'].apply(self.scale_image)\n",
      "/var/folders/4d/hx_5zpz14q7bx518_v0994xc0000gn/T/ipykernel_33983/2152103249.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.images['normalized_image'] = self.images['scaled_image'].apply(self.normalize_image)\n"
     ]
    }
   ],
   "source": [
    "grid_size = (7, 7)  # Define your grid size\n",
    "easy_images = easy_images_df[:5]\n",
    "easy_labels = easy_labels_df[:115]\n",
    "preprocessor = Preprocessor(easy_images, easy_labels, grid_size=grid_size)\n",
    "processed_images_df, processed_labels_df = preprocessor.preprocess()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocessed_labels_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "processed_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_labels_df.rename(columns={'class': 'class_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_images_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Show plot\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 57\u001b[0m plot_circles_on_image_from_df(\u001b[43mprocessed_images_df\u001b[49m, processed_labels_df, grid_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m), image_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_images_df' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def plot_circles_on_image_from_df(processed_images_df, processed_labels_df, grid_size, image_id):\n",
    "    \n",
    "    # Get image data from the DataFrame based on image_id\n",
    "    image_data = processed_images_df.loc[image_id, 'image']\n",
    "    \n",
    "    # Check if image data is None\n",
    "    if image_data is None:\n",
    "        print(\"Error: Image data is None.\")\n",
    "        return\n",
    "    \n",
    "    # Decode image data\n",
    "    image_array = np.array(image_data)\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(image_array)\n",
    "    \n",
    "    # Get image height and width\n",
    "    image_height, image_width = image_array.shape[:2]\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    grid_width = image_width / grid_size[1]\n",
    "    grid_height = image_height / grid_size[0]\n",
    "    \n",
    "    # Get labels for the selected image\n",
    "    image_labels = processed_labels_df[processed_labels_df['image_id'] == image_id]\n",
    "    \n",
    "    # Iterate through labels\n",
    "    scale_factor = 0.5\n",
    "    \n",
    "    for label in image_labels.itertuples():\n",
    "        # Get relative coordinates and radius\n",
    "        relative_x, relative_y, relative_radius = label.relative_x, label.relative_y, label.red_radius\n",
    "        \n",
    "        # Calculate the grid indices\n",
    "        grid_x = int(label.x/grid_width)\n",
    "        grid_y = int(label.y/grid_height)\n",
    "        \n",
    "        # Calculate absolute coordinates\n",
    "        absolute_x = (grid_x + relative_x) * grid_width\n",
    "        absolute_y = (grid_y + relative_y) * grid_height\n",
    "        absolute_r = relative_radius * 2\n",
    "        \n",
    "        # Plot circle\n",
    "        circle = plt.Circle((absolute_x, absolute_y), absolute_r, color='y', fill=False)\n",
    "        ax.add_artist(circle)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "plot_circles_on_image_from_df(processed_images_df, processed_labels_df, grid_size=(7, 7), image_id=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Preprocessor(easy_images_df, easy_labels_df, grid_size = (7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Preprocessor at 0x151c6a5d0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size = 32, shuffle = True ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m      2\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnormalised_image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(labels\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
     ]
    }
   ],
   "source": [
    "for batch in data_loader:\n",
    "    images, labels = batch\n",
    "    print(images.shape)\n",
    "    print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
